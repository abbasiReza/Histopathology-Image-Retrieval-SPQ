{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"wJGA-w3nwUEF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646552869078,"user_tz":-210,"elapsed":3281,"user":{"displayName":"reza abbasi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16461171515024221393"}},"outputId":"54ef501d-f8cb-4503-ff15-3ee3b29f4e08"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"wJGA-w3nwUEF"},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":408,"status":"ok","timestamp":1646552876193,"user":{"displayName":"reza abbasi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16461171515024221393"},"user_tz":-210},"id":"EG5tDT36w3xx","outputId":"8a3733a9-e8c3-460e-b0b6-1a0f11378b92"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/drive/MyDrive/models/SPQ\n"]}],"source":["!pwd \n","%cd drive/MyDrive/models/SPQ/"],"id":"EG5tDT36w3xx"},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4273,"status":"ok","timestamp":1646552162592,"user":{"displayName":"reza abbasi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16461171515024221393"},"user_tz":-210},"id":"klp1SlNZxQYJ","outputId":"6b6499ea-43c6-4386-c9ec-15db2d9a5573"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting kornia\n","  Downloading kornia-0.6.3-py2.py3-none-any.whl (474 kB)\n","\u001b[?25l\r\u001b[K     |▊                               | 10 kB 21.8 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 20 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |██                              | 30 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 40 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 51 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 61 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 71 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 81 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 92 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████                         | 102 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 112 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 122 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 133 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 143 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 153 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 163 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 174 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 184 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 194 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 204 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 215 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 225 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 235 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 245 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 256 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 266 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 276 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 286 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 296 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 307 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 317 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 327 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 337 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 348 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 358 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 368 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 378 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 389 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 399 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 409 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 419 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 430 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 440 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 450 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 460 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 471 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 474 kB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from kornia) (21.3)\n","Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from kornia) (1.10.0+cu111)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.8.1->kornia) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->kornia) (3.0.7)\n","Installing collected packages: kornia\n","Successfully installed kornia-0.6.3\n"]}],"source":["!pip install kornia"],"id":"klp1SlNZxQYJ"},{"cell_type":"code","execution_count":3,"metadata":{"id":"ge0URpIOE_ak","executionInfo":{"status":"ok","timestamp":1646552879180,"user_tz":-210,"elapsed":1415,"user":{"displayName":"reza abbasi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16461171515024221393"}}},"outputs":[],"source":["import torch\n","torch.cuda.empty_cache()"],"id":"ge0URpIOE_ak"},{"cell_type":"code","execution_count":4,"metadata":{"id":"kvOUzHCeElSa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646552880203,"user_tz":-210,"elapsed":6,"user":{"displayName":"reza abbasi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16461171515024221393"}},"outputId":"a2b231fc-43ec-494b-8798-cde72240b8cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Mar  6 07:47:58 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   53C    P0    35W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"],"id":"kvOUzHCeElSa"},{"cell_type":"code","execution_count":5,"metadata":{"id":"352051e5","executionInfo":{"status":"ok","timestamp":1646552883197,"user_tz":-210,"elapsed":886,"user":{"displayName":"reza abbasi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16461171515024221393"}}},"outputs":[],"source":["from utils import *\n","from tqdm import tqdm\n","from dataset import SingleData\n","import math\n","\n","def get_data_list(data_path, ratio=0.0):\n","    img_list = []\n","    for root, dirs, files in os.walk(data_path):\n","        if files == []:\n","            class_name = dirs\n","        elif dirs == []:\n","            for f in files:\n","                img_path = os.path.join(root, f)\n","                img_list.append(img_path)\n","\n","    np.random.seed(1)\n","    train_img_list = np.random.choice(img_list, size=int(len(img_list)*(1-ratio)), replace=False)\n","    #print(img_list, train_img_list)\n","    eval_img_list = list(set(img_list) - set(train_img_list))\n","    ########add\n","    half=math.floor(len(eval_img_list)/2)\n","    print(half)\n","    eval_=eval_img_list[:half]\n","    test_=eval_img_list[half:]\n","    #######\n","    #return class_name, train_img_list, eval_img_list \n","    return class_name, train_img_list\n","\n","def pqDist_one(C, N_books, g_x, q_x,query_pname,gallery_pname):\n","    l1, l2 = C.shape\n","    L_word = int(l2/N_books)\n","    D_C = T.zeros((l1, N_books), dtype=T.float32)\n","\n","    q_x_split = T.split(q_x, L_word, 0)\n","    g_x_split = np.split(g_x.cpu().data.numpy(), N_books, 1)\n","    C_split = T.split(C, L_word, 1)\n","    D_C_split = T.split(D_C, 1, 1)\n","\n","    for j in range(N_books):\n","        for k in range(l1):\n","            # D_C_split[j][k] =T.norm(q_x_split[j]-C_split[j][k], 2)\n","            D_C_split[j][k] = T.norm(q_x_split[j]-C_split[j][k], 2).detach() #for PyTorch version over 1.9\n","        if j == 0:\n","            dist = D_C_split[j][g_x_split[j]]\n","        else:\n","            dist = T.add(dist, D_C_split[j][g_x_split[j]])\n","    Dpq = T.squeeze(dist)\n","#     ##### TASK\n","#     for i in range(len(gallery_pname)):\n","#         if query_pname==gallery_pname[i]:\n","#             Dpq[i]=float('inf')\n","#     #####\n","    return Dpq\n","\n","def Indexing(C, N_books, X):\n","    l1, l2 = C.shape\n","    L_word = int(l2/N_books)\n","    x = T.split(X, L_word, 1)\n","    y = T.split(C, L_word, 1)\n","    for i in range(N_books):\n","        diff = squared_distances(x[i], y[i])\n","        arg = T.argmin(diff, dim=1)\n","        min_idx = T.reshape(arg, [-1, 1])\n","        if i == 0:\n","            quant_idx = min_idx\n","        else:\n","            quant_idx = T.cat((quant_idx, min_idx), dim=1)\n","    return quant_idx\n","\n","def Evaluate_mAP(C, N_books, gallery_codes, query_codes, gallery_labels, query_labels, device,gallery_pname,query_pname, TOP_K=None):\n","    num_query = query_labels.shape[0]\n","    mean_AP = 0.0\n","\n","    with tqdm(total=num_query, desc=\"Evaluate mAP\", bar_format='{desc:<15}{percentage:3.0f}%|{bar:10}{r_bar}') as pbar:\n","        for i in range(num_query):\n","            # Retrieve images from database\n","            retrieval = (query_labels[i, :] @ gallery_labels.t() > 0).float()\n","\n","            # Arrange position according to hamming distance\n","            retrieval = retrieval[T.argsort(pqDist_one(C, N_books, gallery_codes, query_codes[i],query_pname[i],gallery_pname))][:TOP_K]\n","\n","            # Retrieval count\n","            retrieval_cnt = retrieval.sum().int().item()\n","\n","            # Can not retrieve images\n","            if retrieval_cnt == 0:\n","                continue\n","\n","            # Generate score for every position\n","            score = T.linspace(1, retrieval_cnt, retrieval_cnt).to(device)\n","\n","            # Acquire index\n","            index = (T.nonzero(retrieval == 1, as_tuple=False).squeeze() + 1.0).float().to(device)\n","\n","            mean_AP += (score / index).mean()\n","            pbar.update(1)\n","\n","        mean_AP = mean_AP / num_query\n","    return mean_AP\n","\n","def DoRetrieval(device, args, net, C):\n","    print(\"Do Retrieval!\")\n","\n","\n","    class_name, train_img_list = get_data_list('content/drive/MyDrive/dataSets/CRC/train')\n","    train_data_set=SingleData(class_name, train_img_list, transform=transforms.ToTensor())\n","    Gallery_loader = T.utils.data.DataLoader(train_data_set, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers)\n","\n","    # trainset = torchvision.datasets.CIFAR10(root=args.data_dir, train=True, download=args.if_download, transform=transforms.ToTensor())\n","    # Gallery_loader = T.utils.data.DataLoader(trainset, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers)\n","    class_test_name, test_img_list = get_data_list('content/drive/MyDrive/dataSets/CRC/same test')\n","    test_data_set = SingleData(class_test_name, test_img_list, transform=transforms.ToTensor())    \n","    \n","    # testset = torchvision.datasets.CIFAR10(root=args.data_dir, train=False, download=args.if_download, transform=transforms.ToTensor())\n","    Query_loader = T.utils.data.DataLoader(test_data_set, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers)\n","\n","    net.eval()\n","    with T.no_grad():\n","        with tqdm(total=len(Gallery_loader), desc=\"Build Gallery\", bar_format='{desc:<15}{percentage:3.0f}%|{bar:10}{r_bar}') as pbar:\n","            for i, data in enumerate(Gallery_loader, 0):\n","                gallery_x_batch, gallery_y_batch = data[0].to(device), data[1].to(device)\n","                gallery_y_batch=gallery_y_batch.long()\n","                outputs = net(gallery_x_batch)\n","                gallery_c_batch = Indexing(C, args.N_books, outputs[0])\n","                gallery_y_batch = T.eye(args.num_cls)[gallery_y_batch]\n","                temp=[]\n","                for s in data[2]:\n","                    index1=s.rfind('/')\n","                    temp.append(s[index1+4:index1+7])\n","                    print(s[index1+4:index1+7])\n","                    \n","                if i == 0:\n","                    gallery_c = gallery_c_batch\n","                    gallery_y = gallery_y_batch\n","                    gallery_pname=temp\n","                else:\n","                    gallery_c = T.cat([gallery_c, gallery_c_batch], 0)\n","                    gallery_y = T.cat([gallery_y, gallery_y_batch], 0)\n","                    gallery_pname=gallery_pname + temp\n","                pbar.update(1)\n","\n","        with tqdm(total=len(Query_loader), desc=\"Compute Query\", bar_format='{desc:<15}{percentage:3.0f}%|{bar:10}{r_bar}') as pbar:\n","            for i, data in enumerate(Query_loader, 0):\n","                query_x_batch, query_y_batch = data[0].to(device), data[1].to(device)\n","                query_y_batch=query_y_batch.long()\n","                outputs = net(query_x_batch)\n","                query_y_batch = T.eye(args.num_cls)[query_y_batch]\n","                \n","                temp=[]\n","                for s in data[2]:\n","                    index1=s.rfind('/')\n","                    temp.append(s[index1+4:index1+7])\n","                    \n","\n","                if i == 0:\n","                    query_c = outputs[0]\n","                    query_y = query_y_batch\n","                    query_pname=temp\n","                else:\n","                    query_c = T.cat([query_c, outputs[0]], 0)\n","                    query_y = T.cat([query_y, query_y_batch], 0)\n","                    query_pname=query_pname+temp\n","                pbar.update(1)\n","\n","    mAP = Evaluate_mAP(C, args.N_books, gallery_c.type(T.int), query_c, gallery_y, query_y, device,gallery_pname,query_pname, args.Top_N)\n","    return mAP\n"],"id":"352051e5"},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"62f798a7","scrolled":true,"outputId":"3430209d-fadd-4746-fd96-a1c38976ae33","executionInfo":{"status":"ok","timestamp":1646552901551,"user_tz":-210,"elapsed":8821,"user":{"displayName":"reza abbasi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16461171515024221393"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[91m32-bit to retrieval\u001b[0m\n","0\n","['s1', 's2', 's3']\n","Epoch: 350, Learning rate: 0.0003\n","torch.Size([32, 512, 27, 27])\n","torch.Size([32, 512, 1, 1])\n","torch.Size([32, 512])\n","torch.Size([32, 512])\n"]}],"source":["from torch.optim.lr_scheduler import CosineAnnealingLR\n","from utils import *\n","from Retrieval import *\n","from dataset import SingleData\n","import math\n","\n","\n","def get_data_list(data_path, ratio=0.0):\n","    img_list = []\n","    for root, dirs, files in os.walk(data_path):\n","        if files == []:\n","            class_name = dirs\n","        elif dirs == []:\n","            for f in files:\n","                img_path = os.path.join(root, f)\n","                img_list.append(img_path)\n","\n","    np.random.seed(1)\n","    train_img_list = np.random.choice(img_list, size=int(len(img_list)*(1-ratio)), replace=False)\n","    #print(img_list, train_img_list)\n","    eval_img_list = list(set(img_list) - set(train_img_list))\n","    ########add\n","    half=math.floor(len(eval_img_list)/2)\n","    print(half)\n","    eval_=eval_img_list[:half]\n","    test_=eval_img_list[half:]\n","    #######\n","    #return class_name, train_img_list, eval_img_list \n","    return class_name, train_img_list\n","\n","\n","def get_args_parser():\n","    parser = argparse.ArgumentParser('SPQ', add_help=False)\n","\n","    parser.add_argument('--gpu_id', default=\"0\", type=str, help=\"\"\"Define GPU id.\"\"\")\n","    parser.add_argument('--if_download', default=False, type=bool, help=\"\"\"Whether to download the dataset or not.\"\"\")\n","    parser.add_argument('--data_dir', default=\"./data\", type=str, help=\"\"\"Path of the dataset to be installed.\"\"\")\n","    # parser.add_argument('--batch_size', default=256, type=int, help=\"\"\"Training mini-batch size.\"\"\")\n","    parser.add_argument('--batch_size', default=32, type=int, help=\"\"\"Training mini-batch size.\"\"\")\n","    parser.add_argument('--num_workers', default=4, type=int, help=\"\"\"Number of data loading workers per GPU.\"\"\")\n","    parser.add_argument('--input_size', default=216, type=int, help=\"\"\"Input image size, default is set to CIFAR10.\"\"\")\n","\n","    parser.add_argument('--N_books', default=8, type=int, help=\"\"\"The number of the codebooks.\"\"\")\n","    parser.add_argument('--N_words', default=16, type=int, help=\"\"\"The number of the codewords. It should be a power of two.\"\"\")\n","    parser.add_argument('--L_word', default=16, type=int, help=\"\"\"Dimensionality of the codeword.\"\"\")\n","    parser.add_argument('--soft_quantization_scale', default=5.0, type=float, help=\"\"\"Soft-quantization scaling parameter.\"\"\")\n","    parser.add_argument('--contrastive_temperature', default=0.5, type=float, help=\"\"\"Contrastive learning Temperature scaling parameter.\"\"\")\n","    \n","    parser.add_argument('--num_cls', default=\"3\", type=int, help=\"\"\"The number of classes in the dataset for evaluation, default is set to CIFAR10\"\"\")\n","    parser.add_argument('--eval_epoch', default=50, type=int, help=\"\"\"Compute mAP for Every N-th epoch.\"\"\")\n","    # parser.add_argument('--eval_epoch', default=100, type=int, help=\"\"\"Compute mAP for Every N-th epoch.\"\"\")\n","    parser.add_argument('--output_dir', default=\".\", type=str, help=\"\"\"Path to save logs and checkpoints.\"\"\")\n","    parser.add_argument('--Top_N', default=100, type=int, help=\"\"\"Top N number of images to be retrieved for evaluation.\"\"\")\n","    \n","    return parser\n","class CQCLoss(T.nn.Module):\n","\n","    def __init__(self, device, batch_size, tau_cqc):\n","        super(CQCLoss, self).__init__()\n","        self.batch_size = batch_size\n","        self.tau_cqc = tau_cqc\n","        self.device = device\n","        self.COSSIM = T.nn.CosineSimilarity(dim=-1)\n","        self.CE = T.nn.CrossEntropyLoss(reduction=\"sum\")\n","        self.get_corr_mask = self._get_correlated_mask().type(T.bool)\n","\n","    def _get_correlated_mask(self):\n","        diag = np.eye(2 * self.batch_size)\n","        l1 = np.eye((2 * self.batch_size), 2 * self.batch_size, k=-self.batch_size)\n","        l2 = np.eye((2 * self.batch_size), 2 * self.batch_size, k=self.batch_size)\n","        mask = T.from_numpy((diag + l1 + l2))\n","        mask = (1 - mask).type(T.bool)\n","        return mask.to(self.device)\n","\n","    def forward(self, Xa, Xb, Za, Zb):\n","\n","        XaZb = T.cat([Xa, Zb], dim=0)\n","        XbZa = T.cat([Xb, Za], dim=0)\n","\n","        Cossim_ab = self.COSSIM(XaZb.unsqueeze(1), XaZb.unsqueeze(0))\n","        Rab = T.diag(Cossim_ab, self.batch_size)\n","        Lab = T.diag(Cossim_ab, -self.batch_size)\n","        Pos_ab = T.cat([Rab, Lab]).view(2 * self.batch_size, 1)\n","        Neg_ab = Cossim_ab[self.get_corr_mask].view(2 * self.batch_size, -1)\n","\n","        Cossim_ba = self.COSSIM(XbZa.unsqueeze(1), XbZa.unsqueeze(0))\n","        Rba = T.diag(Cossim_ba, self.batch_size)\n","        Lba = T.diag(Cossim_ba, -self.batch_size)    \n","        Pos_ba = T.cat([Rba, Lba]).view(2 * self.batch_size, 1)\n","        Neg_ba = Cossim_ba[self.get_corr_mask].view(2 * self.batch_size, -1)\n","\n","\n","        logits_ab = T.cat((Pos_ab, Neg_ab), dim=1)\n","        logits_ab /= self.tau_cqc\n","\n","        logits_ba = T.cat((Pos_ba, Neg_ba), dim=1)\n","        logits_ba /= self.tau_cqc\n","\n","        labels = T.zeros(2 * self.batch_size).to(self.device).long()\n","        \n","        loss = self.CE(logits_ab, labels) + self.CE(logits_ba, labels)\n","        return loss / (2 * self.batch_size)\n","\n","def train_SPQ(args):\n","    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu_id\n","    device = T.device('cuda')\n","    # device = xm.xla_device()\n","\n","    sz = args.input_size\n","    data_dir = args.data_dir\n","    batch_size = args.batch_size\n","\n","    N_books = args.N_books\n","    N_words = args.N_words\n","    L_word = args.L_word\n","    tau_q = args.soft_quantization_scale\n","    tau_cqc = args.contrastive_temperature\n","\n","    N_bits = int(N_books * np.sqrt(N_words))\n","    print('\\033[91m' + '%d'%N_bits +  '-bit to retrieval' + '\\033[0m')\n","\n","    #Define the data augmentation following the setup of SimCLR\n","    Augmentation = nn.Sequential(\n","        Kg.RandomResizedCrop(size=(sz, sz)),\n","        Kg.RandomHorizontalFlip(p=0.5),\n","        Kg.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1, p=0.8),\n","        Kg.RandomGrayscale(p=0.2),\n","        Kg.RandomGaussianBlur((int(0.1 * sz), int(0.1 * sz)), (0.1, 2.0), p=0.5))\n","\n","    transform = transforms.ToTensor()\n","    \n","    class_name, train_img_list = get_data_list('/content/drive/MyDrive/dataSets/CRC/train/')\n","    train_data_set=SingleData(class_name, train_img_list, transform)\n","    \n","    # trainset = torchvision.datasets.CIFAR10(root=data_dir, train=True, download=args.if_download, transform=transform)\n","    trainloader = T.utils.data.DataLoader(train_data_set, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=args.num_workers)\n","    # trainloader = T.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=args.num_workers)\n","    # testset = torchvision.datasets.CIFAR10(root=args.data_dir, train=False, download=args.if_download, transform=transforms.ToTensor())\n","    class Quantization_Head(nn.Module):\n","        def __init__(self, N_words, N_books, L_word, tau_q):\n","            super(Quantization_Head, self).__init__()\n","            self.fc = nn.Linear(512, N_books * L_word)\n","            nn.init.xavier_uniform_(self.fc.weight)\n","\n","            # Codebooks\n","            self.C = T.nn.Parameter(Variable((T.randn(N_words, N_books * L_word)).type(T.float32), requires_grad=True))\n","            nn.init.xavier_uniform_(self.C)\n","\n","            self.N_books = N_books\n","            self.L_word = L_word\n","            self.tau_q = tau_q\n","\n","        def forward(self, input):\n","            X = self.fc(input)\n","            Z = Soft_Quantization(X, self.C, self.N_books, self.tau_q)\n","            return X, Z\n","        \n","    Q = Quantization_Head(N_words, N_books, L_word, tau_q)\n","    net = nn.Sequential(ResNet_Baseline(BasicBlock, [2, 2, 2, 2]), Q)\n","    net.load_state_dict(T.load('/content/drive/MyDrive/models/SPQ/349_32_0.1871_checkpoint.pth'))\n","    net.cuda(device)\n","    # mx    = xmp.MpModelWrapper(net)\n","    # net  = mx.to(device)\n","\n","    criterion = CQCLoss(device, batch_size, tau_cqc)\n","\n","    optimizer = T.optim.Adam(net.parameters(), lr=3e-4, weight_decay=10e-6)\n","    scheduler = CosineAnnealingLR(optimizer, T_max=len(trainloader), eta_min=0, last_epoch=-1)\n","\n","    MAX_mAP = 0.0\n","    mAP = 0.0\n","\n","    for epoch in range(350,600):  # loop over the dataset multiple times\n","\n","        print('Epoch: %d, Learning rate: %.4f' % (epoch, scheduler.get_last_lr()[0]))\n","        running_loss = 0.0\n","\n","        for i, data in enumerate(trainloader, 0):\n","            inputs = data[0].to(device)\n","            Ia = Augmentation(inputs)\n","            Ib = Augmentation(inputs)\n","\n","            optimizer.zero_grad()\n","\n","            Xa, Za = net(Ia)\n","           \n","            return 1;\n","        #     Xb, Zb = net(Ib)\n","\n","        #     loss = criterion(Xa, Xb, Za, Zb)\n","        #     loss.backward()\n","        #     optimizer.step()\n","\n","        #     running_loss += loss.item()\n","\n","        #     if (i+1) % 10 == 0:    # print every 10 mini-batches\n","        #         print('[%3d] loss: %.4f, mAP: %.4f, MAX mAP: %.4f' %\n","        #             (i+1, running_loss / 10, mAP, MAX_mAP))\n","        #         running_loss = 0.0\n","\n","        # if epoch >= 10:\n","        #     scheduler.step()\n","        \n","        # if (epoch+1) % args.eval_epoch == 0:\n","        #     mAP = DoRetrieval(device, args, net, Q.C)\n","        #     if mAP > MAX_mAP:\n","        #         Result_path = os.path.join(args.output_dir, \"%d_%d_%.4f_checkpoint.pth\"%(epoch,N_bits, mAP))\n","        #         T.save(net.state_dict(), Result_path)\n","        #         MAX_mAP = mAP\n","\n","if __name__ == '__main__':\n","    parser = argparse.ArgumentParser('SPQ', parents=[get_args_parser()])\n","    args = parser.parse_args(\"\")\n","    train_SPQ(args)\n"],"id":"62f798a7"},{"cell_type":"code","execution_count":null,"metadata":{"id":"30a129f1","outputId":"e9d33997-35e2-46bd-ca56-b2b01702ced2"},"outputs":[{"ename":"NameError","evalue":"name 'mAP' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5964/3263977451.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmAP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;31mNameError\u001b[0m: name 'mAP' is not defined"]}],"source":["model.load_state_dict(torch.load(weight_path))"],"id":"30a129f1"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ca0099fe","outputId":"5ea9fbbb-5704-4131-c599-48ec640789ba"},"outputs":[{"name":"stdout","output_type":"stream","text":["Namespace(gpu_id='0', if_download=False, data_dir='./data', batch_size=32, num_workers=8, input_size=96, N_books=8, N_words=16, L_word=16, soft_quantization_scale=5.0, contrastive_temperature=0.5, num_cls=3, eval_epoch=50, output_dir='.', Top_N=8)\n"]}],"source":["print(args)"],"id":"ca0099fe"},{"cell_type":"code","execution_count":null,"metadata":{"id":"8a4f2551","outputId":"5de281d9-cf33-4c8c-8af4-fd22953bb247"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[91m32-bit to retrieval\u001b[0m\n","0\n","['s1', 's2', 's3']\n"]}],"source":["os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu_id\n","device = T.device('cuda')\n","\n","sz = args.input_size\n","data_dir = args.data_dir\n","batch_size = args.batch_size\n","\n","N_books = args.N_books\n","N_words = args.N_words\n","L_word = args.L_word\n","tau_q = args.soft_quantization_scale\n","tau_cqc = args.contrastive_temperature\n","\n","N_bits = int(N_books * np.sqrt(N_words))\n","print('\\033[91m' + '%d'%N_bits +  '-bit to retrieval' + '\\033[0m')\n","\n","#Define the data augmentation following the setup of SimCLR\n","Augmentation = nn.Sequential(\n","    Kg.RandomResizedCrop(size=(sz, sz)),\n","    Kg.RandomHorizontalFlip(p=0.5),\n","    Kg.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1, p=0.8),\n","    Kg.RandomGrayscale(p=0.2),\n","    Kg.RandomGaussianBlur((int(0.1 * sz), int(0.1 * sz)), (0.1, 2.0), p=0.5))\n","\n","transform = transforms.ToTensor()\n","\n","class_name, train_img_list = get_data_list('D:\\\\original_images_5\\\\test-patches\\\\trainset\\\\SPQ\\\\final96\\\\train\\\\final')\n","train_data_set=SingleData(class_name, train_img_list, transform)\n","\n","trainset = torchvision.datasets.CIFAR10(root=data_dir, train=True, download=args.if_download, transform=transform)\n","trainloader = T.utils.data.DataLoader(train_data_set, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=args.num_workers)\n","# trainloader = T.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=args.num_workers)\n","testset = torchvision.datasets.CIFAR10(root=args.data_dir, train=False, download=args.if_download, transform=transforms.ToTensor())\n","class Quantization_Head(nn.Module):\n","    def __init__(self, N_words, N_books, L_word, tau_q):\n","        super(Quantization_Head, self).__init__()\n","        self.fc = nn.Linear(512, N_books * L_word)\n","        nn.init.xavier_uniform_(self.fc.weight)\n","\n","        # Codebooks\n","        self.C = T.nn.Parameter(Variable((T.randn(N_words, N_books * L_word)).type(T.float32), requires_grad=True))\n","        nn.init.xavier_uniform_(self.C)\n","\n","        self.N_books = N_books\n","        self.L_word = L_word\n","        self.tau_q = tau_q\n","\n","    def forward(self, input):\n","        X = self.fc(input)\n","        Z = Soft_Quantization(X, self.C, self.N_books, self.tau_q)\n","        return X, Z\n","\n","Q = Quantization_Head(N_words, N_books, L_word, tau_q)\n","net = nn.Sequential(ResNet_Baseline(BasicBlock, [2, 2, 2, 2]), Q)\n","net.load_state_dict(T.load('D:\\\\models\\\\SPQ-main\\\\32_0.6476_checkpoint.pth'))\n","net.cuda(device)\n","\n","criterion = CQCLoss(device, batch_size, tau_cqc)\n","\n","optimizer = T.optim.Adam(net.parameters(), lr=3e-4, weight_decay=10e-6)\n","scheduler = CosineAnnealingLR(optimizer, T_max=len(trainloader), eta_min=0, last_epoch=-1)\n","\n","MAX_mAP = 0.0\n","mAP = 0.0"],"id":"8a4f2551"},{"cell_type":"code","execution_count":null,"metadata":{"id":"42e835d9","outputId":"dee49620-a354-4495-cbcb-3deaa0031829"},"outputs":[{"name":"stdout","output_type":"stream","text":["Do Retrieval!\n","7500\n","['s1', 's2', 's3']\n","15\n","['s1', 's2', 's3']\n"]},{"name":"stderr","output_type":"stream","text":["Build Gallery  100%|██████████| 469/469 [04:57<00:00,  1.58it/s]\n","Compute Query  100%|██████████| 93/93 [01:14<00:00,  1.24it/s]\n","Evaluate mAP    94%|█████████▍| 2805/2970 [02:00<00:07, 23.19it/s]\n"]}],"source":["mAP = DoRetrieval(device, args, net, Q.C)"],"id":"42e835d9"},{"cell_type":"code","execution_count":null,"metadata":{"id":"709b25d5","outputId":"8dbb2c71-9a63-42c4-b047-872eea70eae9"},"outputs":[{"data":{"text/plain":["tensor(0.6476, device='cuda:0')"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["mAP"],"id":"709b25d5"},{"cell_type":"code","execution_count":null,"metadata":{"id":"1f06272d"},"outputs":[],"source":[""],"id":"1f06272d"}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Copy of Task.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":5}